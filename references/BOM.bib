
@misc{la_londe_et_al_clusternet_nodate,
	title = {{ClusterNet} {Supplementary} {Materials}},
	url = {https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/3460-supp.pdf},
	author = {La Londe et al.},
	file = {Full Text:C\:\\Users\\chris\\Zotero\\storage\\YCBEZ5ZA\\La Londe et al. - ClusterNet Supplementary Materials.pdf:application/pdf},
}

@article{brunetti_computer_2018,
	title = {Computer vision and deep learning techniques for pedestrian detection and tracking: {A} survey},
	volume = {300},
	issn = {09252312},
	shorttitle = {Computer vision and deep learning techniques for pedestrian detection and tracking},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S092523121830290X},
	doi = {10.1016/j.neucom.2018.01.092},
	language = {en},
	urldate = {2023-02-16},
	journal = {Neurocomputing},
	author = {Brunetti, Antonio and Buongiorno, Domenico and Trotta, Gianpaolo Francesco and Bevilacqua, Vitoantonio},
	month = jul,
	year = {2018},
	pages = {17--33},
	file = {Brunetti et al. - 2018 - Computer vision and deep learning techniques for p.pdf:C\:\\Users\\chris\\Zotero\\storage\\QZRE3NMZ\\Brunetti et al. - 2018 - Computer vision and deep learning techniques for p.pdf:application/pdf},
}

@article{crutchfield_baboons_2020,
	title = {Baboons on the {Move}: {Enhancing} {Understanding} of {Collective} {Decision} {Making} through {Automated} {Motion} {Detection} from {Aerial} {Drone} {Footage}},
	language = {en},
	author = {Crutchfield, Christopher L and Sutton, Jake and Ngo, Anh and Zadorian, Emmanuel and Hourany, Gabrielle and Nelson, Dylan and Wang, Alvin and McHenry-Crutchfield, Fiona and Forster, Deborah and Strum, Shirley C and Kastner, Ryan and Schurgers, Curt},
	month = oct,
	year = {2020},
	pages = {7},
	file = {Crutchfield et al. - Baboons on the Move Enhancing Understanding of Co.pdf:C\:\\Users\\chris\\Zotero\\storage\\KTXW4D57\\Crutchfield et al. - Baboons on the Move Enhancing Understanding of Co.pdf:application/pdf},
}

@article{fang_motion_2016,
	title = {Motion {Based} {Animal} {Detection} in {Aerial} {Videos}},
	volume = {92},
	issn = {18770509},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050916315629},
	doi = {10.1016/j.procs.2016.07.316},
	abstract = {Computer vision techniques are applied to perform automatic wildlife surveying and animal monitoring. Animal detection in aerial videos is challenging because of the complexity of wild environments. In this paper, a method for moving animal detection is proposed by taking advantage of global patterns of pixel motion. In the video dataset, where animals make obvious movement against the background, motion vectors of each pixel are estimated by applying optical flow methods. A coarse segmentation then removes most parts of the background by applying a pixel velocity threshold. Based on the segmented regions, another threshold was employed to filter out negative candidates that could belong to the background. The pros and cons of this method are discussed.},
	language = {en},
	urldate = {2023-02-15},
	journal = {Procedia Computer Science},
	author = {Fang, Yunfei and Du, Shengzhi and Abdoola, Rishaad and Djouani, Karim and Richards, Coneth},
	year = {2016},
	pages = {13--17},
	file = {Fang et al. - 2016 - Motion Based Animal Detection in Aerial Videos.pdf:C\:\\Users\\chris\\Zotero\\storage\\9DIRJ2XL\\Fang et al. - 2016 - Motion Based Animal Detection in Aerial Videos.pdf:application/pdf},
}

@article{barbu_novel_nodate,
	title = {Novel {Approach} for {Moving} {Human} {Detection} and {Tracking} in {Static} {Camera} {Video} {Sequences}},
	abstract = {An automatic multiple person detection and tracking technique for static camera movies is proposed in this paper. First, a moving human identification method is provided. It detects the video objects by using a novel temporal differencing based algorithm and some morphological processes. Then, our approach decides which moving objects represent walking persons, by computing some human size parameters and extracting some skin segments. A novel human tracking technique using a correlationbased video object matching process is then proposed in this paper.},
	language = {en},
	author = {Barbu, Tudor},
	file = {Barbu - NOVEL APPROACH FOR MOVING HUMAN DETECTION AND TRAC.pdf:C\:\\Users\\chris\\Zotero\\storage\\DTVVQA57\\Barbu - NOVEL APPROACH FOR MOVING HUMAN DETECTION AND TRAC.pdf:application/pdf},
}

@article{fuhr_combining_2014,
	title = {Combining patch matching and detection for robust pedestrian tracking in monocular calibrated cameras},
	volume = {39},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865513003358},
	doi = {10.1016/j.patrec.2013.08.031},
	abstract = {This paper presents a new approach for tracking multiple people in monocular calibrated cameras combining patch matching and pedestrian detection. Initially, background removal and pedestrian detection are used in conjunction with the vertical standing hypothesis to initialize the targets with multiples patches. In the tracking step, each patch related to a given target is matched individually across frames, and their translation vectors are combined robustly with pedestrian detection results in the world coordinate frame using weighted vector median ﬁlters. Additionally, the algorithm uses the camera parameters to both estimate the person scale in a straightforward manner and to limit the search region used to track each fragment. Our experimental results indicate that our tracker can deal with occlusions and video sequences with strong appearance variations, presenting results comparable to or better than existing state-of-the-art algorithms.},
	language = {en},
	urldate = {2023-02-15},
	journal = {Pattern Recognition Letters},
	author = {Führ, Gustavo and Jung, Cláudio Rosito},
	month = apr,
	year = {2014},
	pages = {11--20},
	file = {Führ and Jung - 2014 - Combining patch matching and detection for robust .pdf:C\:\\Users\\chris\\Zotero\\storage\\RL8DNQSP\\Führ and Jung - 2014 - Combining patch matching and detection for robust .pdf:application/pdf},
}

@article{wang_effective_2021,
	title = {Effective multiple pedestrian tracking system in video surveillance with monocular stationary camera},
	volume = {178},
	issn = {09574174},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0957417421004334},
	doi = {10.1016/j.eswa.2021.114992},
	abstract = {Multiple pedestrian tracking in video surveillance is still a pressing challenge, especially under static and dy­ namic occlusions and target appearance variations. Considering these complex environments in video surveil­ lance, a multiple pedestrian tracking system with special processing procedures is proposed in this paper. In the proposed tracking system, pedestrian candidates are detected on each frame and registered as the tracked targets or associated with existing targets when their situations are suitable. The registered pedestrian targets are tracked frame by frame and terminated when the termination criteria are satisfied. In order to distinguish these target individuals, multi-sample adaptive modeling (MSAM) is proposed, which is used to adapt to a new target’s unpredictable pose variation. Furthermore, static occlusions are annotated for each scene, which may occlude pedestrians in the annotated regions. These occluded targets are modified by the assigned rules and treated differently in the process of target association. Aiming to enhance the effect of target association, each target’s location on the current frame is predicted with information on the previous frames using a Kalman filter. The predicted location is regarded as the center of the search region of the corresponding target. The experimental results show that the proposed tracker achieves the best performance among the five state-of-the-art trackers on three publicly available databases.},
	language = {en},
	urldate = {2023-02-15},
	journal = {Expert Systems with Applications},
	author = {Wang, Zhihui and Li, Ming and Lu, Yu and Bao, Yongtang and Li, Zhe and Zhao, Jianli},
	month = sep,
	year = {2021},
	pages = {114992},
	file = {Wang et al. - 2021 - Effective multiple pedestrian tracking system in v.pdf:C\:\\Users\\chris\\Zotero\\storage\\XNFCJHDI\\Wang et al. - 2021 - Effective multiple pedestrian tracking system in v.pdf:application/pdf},
}

@phdthesis{crutchfield_spot_nodate,
	title = {Spot, an algorithm for low resolution, low contrast, moving object tracking from a moving camera},
	language = {en},
	author = {Crutchfield, Christopher Lee},
	file = {Crutchfield - Electrical Engineering (Intelligent System, Roboti.pdf:C\:\\Users\\chris\\Zotero\\storage\\MKZIZ5CZ\\Crutchfield - Electrical Engineering (Intelligent System, Roboti.pdf:application/pdf},
}

@article{suzuki_topological_nodate,
	title = {Topological {Structural} {Analysis} of {Digitized} {Binary} {Images} by {Border} {Following}},
	language = {en},
	author = {Suzuki, Satoshi},
	file = {Suzuki - Topological Structural Analysis of Digitized Binar.pdf:C\:\\Users\\chris\\Zotero\\storage\\6CZCJMAH\\Suzuki - Topological Structural Analysis of Digitized Binar.pdf:application/pdf},
}

@article{yang_small_2016,
	title = {Small {Moving} {Vehicle} {Detection} in a {Satellite} {Video} of an {Urban} {Area}},
	volume = {16},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/16/9/1528},
	doi = {10.3390/s16091528},
	abstract = {Vehicle surveillance of a wide area allows us to learn much about the daily activities and trafﬁc information. With the rapid development of remote sensing, satellite video has become an important data source for vehicle detection, which provides a broader ﬁeld of surveillance. The achieved work generally focuses on aerial video with moderately-sized objects based on feature extraction. However, the moving vehicles in satellite video imagery range from just a few pixels to dozens of pixels and exhibit low contrast with respect to the background, which makes it hard to get available appearance or shape information. In this paper, we look into the problem of moving vehicle detection in satellite imagery. To the best of our knowledge, it is the ﬁrst time to deal with moving vehicle detection from satellite videos. Our approach consists of two stages: ﬁrst, through foreground motion segmentation and trajectory accumulation, the scene motion heat map is dynamically built. Following this, a novel saliency based background model which intensiﬁes moving objects is presented to segment the vehicles in the hot regions. Qualitative and quantitative experiments on sequence from a recent Skybox satellite video dataset demonstrates that our approach achieves a high detection rate and low false alarm simultaneously.},
	language = {en},
	number = {9},
	urldate = {2022-11-02},
	journal = {Sensors},
	author = {Yang, Tao and Wang, Xiwen and Yao, Bowei and Li, Jing and Zhang, Yanning and He, Zhannan and Duan, Wencheng},
	month = sep,
	year = {2016},
	pages = {1528},
	file = {Yang et al. - 2016 - Small Moving Vehicle Detection in a Satellite Vide.pdf:C\:\\Users\\chris\\Zotero\\storage\\Q7VLBZQ9\\Yang et al. - 2016 - Small Moving Vehicle Detection in a Satellite Vide.pdf:application/pdf},
}

@inproceedings{kopsiaftis_vehicle_2015,
	address = {Milan, Italy},
	title = {Vehicle detection and traffic density monitoring from very high resolution satellite video data},
	isbn = {978-1-4799-7929-5},
	url = {http://ieeexplore.ieee.org/document/7326160/},
	doi = {10.1109/IGARSS.2015.7326160},
	language = {en},
	urldate = {2022-11-02},
	booktitle = {2015 {IEEE} {International} {Geoscience} and {Remote} {Sensing} {Symposium} ({IGARSS})},
	publisher = {IEEE},
	author = {Kopsiaftis, George and Karantzalos, Konstantinos},
	month = jul,
	year = {2015},
	pages = {1881--1884},
	file = {Kopsiaftis and Karantzalos - 2015 - Vehicle detection and traffic density monitoring f.pdf:C\:\\Users\\chris\\Zotero\\storage\\VAC3VEC3\\Kopsiaftis and Karantzalos - 2015 - Vehicle detection and traffic density monitoring f.pdf:application/pdf},
}

@article{zhu_big_2019,
	title = {Big {Data} {Analytics} in {Intelligent} {Transportation} {Systems}: {A} {Survey}},
	volume = {20},
	issn = {1524-9050, 1558-0016},
	shorttitle = {Big {Data} {Analytics} in {Intelligent} {Transportation} {Systems}},
	url = {https://ieeexplore.ieee.org/document/8344848/},
	doi = {10.1109/TITS.2018.2815678},
	abstract = {Big data is becoming a research focus in intelligent transportation systems (ITS), which can be seen in many projects around the world. Intelligent transportation systems will produce a large amount of data. The produced big data will have profound impacts on the design and application of intelligent transportation systems, which makes ITS safer, more efﬁcient, and proﬁtable. Studying big data analytics in ITS is a ﬂourishing ﬁeld. This paper ﬁrst reviews the history and characteristics of big data and intelligent transportation systems. The framework of conducting big data analytics in ITS is discussed next, where the data source and collection methods, data analytics methods and platforms, and big data analytics application categories are summarized. Several case studies of big data analytics applications in intelligent transportation systems, including road trafﬁc accidents analysis, road trafﬁc ﬂow prediction, public transportation service plan, personal travel route plan, rail transportation management and control, and assets maintenance are introduced. Finally, this paper discusses some open challenges of using big data analytics in ITS.},
	language = {en},
	number = {1},
	urldate = {2022-11-02},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Zhu, Li and Yu, Fei Richard and Wang, Yige and Ning, Bin and Tang, Tao},
	month = jan,
	year = {2019},
	pages = {383--398},
	file = {Zhu et al. - 2019 - Big Data Analytics in Intelligent Transportation S.pdf:C\:\\Users\\chris\\Zotero\\storage\\Y5SBD4N4\\Zhu et al. - 2019 - Big Data Analytics in Intelligent Transportation S.pdf:application/pdf},
}

@inproceedings{hua_vehicle_2018,
	address = {Salt Lake City, UT, USA},
	title = {Vehicle {Tracking} and {Speed} {Estimation} from {Traffic} {Videos}},
	isbn = {978-1-5386-6100-0},
	url = {https://ieeexplore.ieee.org/document/8575446/},
	doi = {10.1109/CVPRW.2018.00028},
	abstract = {The rapid recent advancements in the computation ability of everyday computers have made it possible to widely apply deep learning methods to the analysis of trafﬁc surveillance videos. Trafﬁc ﬂow prediction, anomaly detection, vehicle re-identiﬁcation, and vehicle tracking are basic components in trafﬁc analysis. Among these applications, trafﬁc ﬂow prediction, or vehicle speed estimation, is one of the most important research topics of recent years. Good solutions to this problem could prevent trafﬁc collisions and help improve road planning by better estimating transit demand. In the 2018 NVIDIA AI City Challenge, we combine modern deep learning models with classic computer vision approaches to propose an efﬁcient way to predict vehicle speed. In this paper, we introduce some state-of-the-art approaches in vehicle speed estimation, vehicle detection, and object tracking, as well as our solution for Track 1 of the Challenge.},
	language = {en},
	urldate = {2022-11-02},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} {Workshops} ({CVPRW})},
	publisher = {IEEE},
	author = {Hua, Shuai and Kapoor, Manika and Anastasiu, David C.},
	month = jun,
	year = {2018},
	pages = {153--1537},
	file = {Hua et al. - 2018 - Vehicle Tracking and Speed Estimation from Traffic.pdf:C\:\\Users\\chris\\Zotero\\storage\\W52356FH\\Hua et al. - 2018 - Vehicle Tracking and Speed Estimation from Traffic.pdf:application/pdf},
}

@article{zhou_anomalynet_2019,
	title = {{AnomalyNet}: {An} {Anomaly} {Detection} {Network} for {Video} {Surveillance}},
	volume = {14},
	issn = {1556-6013, 1556-6021},
	shorttitle = {{AnomalyNet}},
	url = {https://ieeexplore.ieee.org/document/8649753/},
	doi = {10.1109/TIFS.2019.2900907},
	abstract = {Sparse coding-based anomaly detection has shown promising performance, of which the keys are feature learning, sparse representation, and dictionary learning. In this paper, we propose a new neural network for anomaly detection (termed AnomalyNet) by deeply achieving feature learning, sparse representation, and dictionary learning in three joint neural processing blocks. Speciﬁcally, to learn better features, we design a motion fusion block accompanied by a feature transfer block to enjoy the advantages of eliminating noisy background, capturing motion, and alleviating data deﬁciency. Furthermore, to address some disadvantages (e.g., nonadaptive updating) of the existing sparse coding optimizers and embrace the merits of neural network (e.g., parallel computing), we design a novel recurrent neural network to learn sparse representation and dictionary by proposing an adaptive iterative hard-thresholding algorithm (adaptive ISTA) and reformulating the adaptive ISTA as a new long short-term memory (LSTM). To the best of our knowledge, this could be one of the ﬁrst works to bridge the 1-solver and LSTM and may provide novel insight into understanding LSTM and model-based optimization (or named differentiable programming), as well as sparse coding-based anomaly detection. Extensive experiments show the state-of-the-art performance of our method in the abnormal events detection task.},
	language = {en},
	number = {10},
	urldate = {2022-11-02},
	journal = {IEEE Transactions on Information Forensics and Security},
	author = {Zhou, Joey Tianyi and Du, Jiawei and Zhu, Hongyuan and Peng, Xi and Liu, Yong and Goh, Rick Siow Mong},
	month = oct,
	year = {2019},
	pages = {2537--2550},
	file = {Zhou et al. - 2019 - AnomalyNet An Anomaly Detection Network for Video.pdf:C\:\\Users\\chris\\Zotero\\storage\\NECKFJA2\\Zhou et al. - 2019 - AnomalyNet An Anomaly Detection Network for Video.pdf:application/pdf},
}

@incollection{leonardis_machine_2006,
	address = {Berlin, Heidelberg},
	title = {Machine {Learning} for {High}-{Speed} {Corner} {Detection}},
	volume = {3951},
	isbn = {978-3-540-33832-1 978-3-540-33833-8},
	url = {http://link.springer.com/10.1007/11744023\_34},
	abstract = {Where feature points are used in real-time frame-rate applications, a high-speed feature detector is necessary. Feature detectors such as SIFT (DoG), Harris and SUSAN are good methods which yield high quality features, however they are too computationally intensive for use in real-time applications of any complexity. Here we show that machine learning can be used to derive a feature detector which can fully process live PAL video using less than 7\% of the available processing time. By comparison neither the Harris detector (120\%) nor the detection stage of SIFT (300\%) can operate at full frame rate.},
	language = {en},
	urldate = {2022-01-25},
	booktitle = {Computer {Vision} – {ECCV} 2006},
	publisher = {Springer Berlin Heidelberg},
	author = {Rosten, Edward and Drummond, Tom},
	editor = {Leonardis, Aleš and Bischof, Horst and Pinz, Axel},
	year = {2006},
	doi = {10.1007/11744023_34},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {430--443},
	file = {Rosten and Drummond - 2006 - Machine Learning for High-Speed Corner Detection.pdf:C\:\\Users\\chris\\Zotero\\storage\\YFMJE4AZ\\Rosten and Drummond - 2006 - Machine Learning for High-Speed Corner Detection.pdf:application/pdf},
}

@article{ester_density-based_nodate,
	title = {A {Density}-{Based} {Algorithm} for {Discovering} {Clusters} in {Large} {Spatial} {Databases} with {Noise}},
	abstract = {Clusteringalgorithmasreattractivefor the taskof classidentification in spatial databases.Howevetrh, e applicationto large spatial databasesrises the followingrequirementfsor clustering algorithms: minimalrequirementsof domain knowledgteo determinethe input parameters,discoveryof clusters witharbitraryshapeandgoodefficiencyonlarge databases. Thewell-knowcnlusteringalgorithmsoffer nosolution to the combinatioonf theserequirementsI.n this paper, wepresent the newclustering algorithmDBSCAreNlying on a density-basednotionof clusters whichis designedto discoverclusters of arbitrary shape.DBSCrAeNquiresonly one input parameterandsupportsthe user in determiningan appropriatevaluefor it. Weperformeadn experimentaelvaluation of the effectiveness and efficiency of DBSCAusNing synthetic data and real data of the SEQUO2IA000benchmark.Theresults of our experimentsdemonstratethat (1) DBSCiAsNsignificantlymoreeffective in discoveringclusters of arbitrary shapethan the well-knowanlgorithmCLARANS,and that (2) DBSCAoNutperforms CLARANbyS factorof morethan100in termsof efficiency.},
	language = {en},
	author = {Ester, Martin and Kriegel, Hans-Peter and Xu, Xiaowei},
	pages = {6},
	file = {Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:C\:\\Users\\chris\\Zotero\\storage\\NWSTK4XA\\Ester et al. - A Density-Based Algorithm for Discovering Clusters.pdf:application/pdf},
}

@article{strandburg-peshkin_shared_2015,
	title = {Shared decision-making drives collective movement in wild baboons},
	volume = {348},
	issn = {0036-8075, 1095-9203},
	url = {https://www.science.org/doi/10.1126/science.aaa5099},
	doi = {10.1126/science.aaa5099},
	abstract = {Baboons follow the pack, not the leader
            
              How do groups of animals, including humans, make decisions that affect the entire group? Evidence collected from schooling animals suggests that the process is somewhat democratic, with nearest neighbors and the majority shaping overall collective behavior. In animals with hierarchical social structures such as primates or wolves, however, such democracy may be complicated by dominance. Strandburg-Peshkin
              et al.
              monitored all the individuals within a baboon troop continuously over the course of their daily activities. Even within this highly socially structured species, movement decisions emerged via a shared process. Thus, democracy may be an inherent trait of collective behavior.
            
            
              Science
              , this issue p.
              1358
            
          , 
            Democracy guides group decisions in baboons, even in the presence of strong social hierarchies.
          , 
            Conflicts of interest about where to go and what to do are a primary challenge of group living. However, it remains unclear how consensus is achieved in stable groups with stratified social relationships. Tracking wild baboons with a high-resolution global positioning system and analyzing their movements relative to one another reveals that a process of shared decision-making governs baboon movement. Rather than preferentially following dominant individuals, baboons are more likely to follow when multiple initiators agree. When conflicts arise over the direction of movement, baboons choose one direction over the other when the angle between them is large, but they compromise if it is not. These results are consistent with models of collective motion, suggesting that democratic collective action emerging from simple rules is widespread, even in complex, socially stratified societies.},
	language = {en},
	number = {6241},
	urldate = {2022-06-24},
	journal = {Science},
	author = {Strandburg-Peshkin, Ariana and Farine, Damien R. and Couzin, Iain D. and Crofoot, Margaret C.},
	month = jun,
	year = {2015},
	pages = {1358--1361},
	file = {Strandburg-Peshkin et al. - 2015 - Shared decision-making drives collective movement .pdf:C\:\\Users\\chris\\Zotero\\storage\\8XV9APES\\Strandburg-Peshkin et al. - 2015 - Shared decision-making drives collective movement .pdf:application/pdf},
}

@incollection{hutchison_detection_2010,
	address = {Berlin, Heidelberg},
	title = {Detection and {Tracking} of {Large} {Number} of {Targets} in {Wide} {Area} {Surveillance}},
	volume = {6313},
	isbn = {978-3-642-15557-4 978-3-642-15558-1},
	url = {http://link.springer.com/10.1007/978-3-642-15558-1\_14},
	abstract = {In this paper, we tackle the problem of object detection and tracking in a new and challenging domain of wide area surveillance. This problem poses several challenges: large camera motion, strong parallax, large number of moving objects, small number of pixels on target, single channel data and low framerate of video. We propose a method that overcomes these challenges and evaluate it on CLIF dataset. We use median background modeling which requires few frames to obtain a workable model. We remove false detections due to parallax and registration errors using gradient information of the background image. In order to keep complexity of the tracking problem manageable, we divide the scene into grid cells, solve the tracking problem optimally within each cell using bipartite graph matching and then link tracks across cells. Besides tractability, grid cells allow us to deﬁne a set of local scene constraints such as road orientation and object context. We use these constraints as part of cost function to solve the tracking problem which allows us to track fast-moving objects in low framerate videos. In addition to that, we manually generated groundtruth for four sequences and performed quantitative evaluation of the proposed algorithm.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {Computer {Vision} – {ECCV} 2010},
	publisher = {Springer Berlin Heidelberg},
	author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Reilly, Vladimir and Idrees, Haroon and Shah, Mubarak},
	editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
	year = {2010},
	doi = {10.1007/978-3-642-15558-1_14},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {186--199},
	file = {Hutchison et al. - 2010 - Detection and Tracking of Large Number of Targets .pdf:C\:\\Users\\chris\\Zotero\\storage\\4CMCG2XJ\\Hutchison et al. - 2010 - Detection and Tracking of Large Number of Targets .pdf:application/pdf},
}

@article{strum_darwins_2012,
	title = {Darwin's monkey: {Why} baboons can't become human},
	volume = {149},
	issn = {00029483},
	shorttitle = {Darwin's monkey},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/ajpa.22158},
	doi = {10.1002/ajpa.22158},
	language = {en},
	number = {S55},
	urldate = {2022-06-24},
	journal = {American Journal of Physical Anthropology},
	author = {Strum, Shirley C.},
	year = {2012},
	pages = {3--23},
	file = {Strum - 2012 - Darwin's monkey Why baboons can't become human.pdf:C\:\\Users\\chris\\Zotero\\storage\\N43K5JHJ\\Strum - 2012 - Darwin's monkey Why baboons can't become human.pdf:application/pdf},
}

@inproceedings{loce_extended_2014,
	address = {San Francisco, California, USA},
	title = {Extended image differencing for change detection in {UAV} video mosaics},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2043209},
	doi = {10.1117/12.2043209},
	urldate = {2022-06-16},
	author = {Saur, Günter and Krüger, Wolfgang and Schumann, Arne},
	editor = {Loce, Robert P. and Saber, Eli},
	month = mar,
	year = {2014},
	pages = {90260L},
}

@article{ao_needles_2020,
	title = {Needles in a {Haystack}: {Tracking} {City}-{Scale} {Moving} {Vehicles} {From} {Continuously} {Moving} {Satellite}},
	volume = {29},
	issn = {1057-7149, 1941-0042},
	shorttitle = {Needles in a {Haystack}},
	url = {https://ieeexplore.ieee.org/document/8861293/},
	doi = {10.1109/TIP.2019.2944097},
	abstract = {In recent years, the satellite videos have been captured by moving satellite platforms. In contrast to consumers, movies, and common surveillance videos, satellite videos can record the snapshots of city-scale scenes. In a broad ﬁeldof-view of satellite videos, each moving target would be very tiny and usually composed of several pixels in frames. Even worse, the noise signals also exist in the video frames, and the background of the video frames subpixel-level and uneven moving thanks to the motion of satellites. We argue that it is a novel type of computer vision task since previous technologies are unable to detect such tiny moving vehicles efﬁciently. This paper proposes a novel framework that can identify small moving vehicles in satellite videos. In particular, we offer a novel detecting algorithm based on the local noise modeling. We differentiate the potential vehicle targets from noise patterns by an exponential probability distribution. Subsequently, a multi-morphologicalcue based discrimination strategy is designed to distinguish correct vehicle targets from the existing noises further. Another signiﬁcant contribution is to introduce a series of evaluation protocols to measure the performance of tiny moving vehicle detection systematically. We annotate satellite videos manually to test our algorithms under different evaluation criterions. The proposed algorithm is also compared with the state-of-the-art baselines, which demonstrates the advantages of our framework over the benchmarks. Besides, the dataset would be downloaded from http://ﬁrst.authour.github.com.},
	language = {en},
	urldate = {2022-06-16},
	journal = {IEEE Transactions on Image Processing},
	author = {Ao, Wei and Fu, Yanwei and Hou, Xiyue and Xu, Feng},
	year = {2020},
	pages = {1944--1957},
	file = {Ao et al. - 2020 - Needles in a Haystack Tracking City-Scale Moving .pdf:C\:\\Users\\chris\\Zotero\\storage\\BPABE4TG\\Ao et al. - 2020 - Needles in a Haystack Tracking City-Scale Moving .pdf:application/pdf},
}

@article{ahmadi_moving_2019,
	title = {Moving vehicle detection, tracking and traffic parameter estimation from a satellite video: a perspective on a smarter city},
	volume = {40},
	issn = {0143-1161, 1366-5901},
	shorttitle = {Moving vehicle detection, tracking and traffic parameter estimation from a satellite video},
	url = {https://www.tandfonline.com/doi/full/10.1080/01431161.2019.1610983},
	doi = {10.1080/01431161.2019.1610983},
	abstract = {Satellite remote sensing is undergoing a revolution in terms of sensors and temporal coverage. The possibility of acquiring earth’s surface video from space provides an opportunity to investigate broader applications of remote sensing. High-resolution spaceborne videos can become a vital factor in earth observation. Temporally continuous tracking of moving objects, i.e. vehicles, vessels, or even military equipment on Earth’s surface demands high spatial resolution satellite videos. Detecting moving vehicles in the urban areas from space video can lead governments to a new era of traﬃc monitoring. Satellite videos will ﬁnd many applications in the ﬁeld of traﬃc monitoring. In this article, ﬁrst, moving vehicles are detected using background subtraction with 94.7\% accuracy. Afterwards, vehicles’ trajectories, average velocities, dynamic velocities, and space-time diagram are estimated and trajectories are classiﬁed based on velocities. Finally, the total frame traﬃc density is computed.},
	language = {en},
	number = {22},
	urldate = {2022-06-16},
	journal = {International Journal of Remote Sensing},
	author = {Ahmadi, Seyed Ali and Ghorbanian, Arsalan and Mohammadzadeh, Ali},
	month = nov,
	year = {2019},
	pages = {8379--8394},
	file = {Ahmadi et al. - 2019 - Moving vehicle detection, tracking and traffic par.pdf:C\:\\Users\\chris\\Zotero\\storage\\DDUS429I\\Ahmadi et al. - 2019 - Moving vehicle detection, tracking and traffic par.pdf:application/pdf},
}

@inproceedings{lalonde_clusternet_2018,
	address = {Salt Lake City, UT, USA},
	title = {{ClusterNet}: {Detecting} {Small} {Objects} in {Large} {Scenes} by {Exploiting} {Spatio}-{Temporal} {Information}},
	isbn = {978-1-5386-6420-9},
	shorttitle = {{ClusterNet}},
	url = {https://ieeexplore.ieee.org/document/8578519/},
	doi = {10.1109/CVPR.2018.00421},
	abstract = {Object detection in wide area motion imagery (WAMI) has drawn the attention of the computer vision research community for a number of years. WAMI proposes a number of unique challenges including extremely small object sizes, both sparse and densely-packed objects, and extremely large search spaces (large video frames). Nearly all state-of-the-art methods in WAMI object detection report that appearance-based classiﬁers fail in this challenging data and instead rely almost entirely on motion information in the form of background subtraction or framedifferencing. In this work, we experimentally verify the failure of appearance-based classiﬁers in WAMI, such as Faster R-CNN and a heatmap-based fully convolutional neural network (CNN), and propose a novel two-stage spatio-temporal CNN which effectively and efﬁciently combines both appearance and motion information to signiﬁcantly surpass the state-of-the-art in WAMI object detection. To reduce the large search space, the ﬁrst stage (ClusterNet) takes in a set of extremely large video frames, combines the motion and appearance information within the convolutional architecture, and proposes regions of objects of interest (ROOBI). These ROOBI can contain from one to clusters of several hundred objects due to the large video frame size and varying object density in WAMI. The second stage (FoveaNet) then estimates the centroid location of all objects in that given ROOBI simultaneously via heatmap estimation. The proposed method exceeds state-of-the-art results on the WPAFB 2009 dataset by 5-16\% for moving objects and nearly 50\% for stopped objects, as well as being the ﬁrst proposed method in wide area motion imagery to detect completely stationary objects.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {2018 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition}},
	publisher = {IEEE},
	author = {LaLonde, Rodney and Zhang, Dong and Shah, Mubarak},
	month = jun,
	year = {2018},
	pages = {4003--4012},
	file = {LaLonde et al. - 2018 - ClusterNet Detecting Small Objects in Large Scene.pdf:C\:\\Users\\chris\\Zotero\\storage\\HZUVKBDC\\LaLonde et al. - 2018 - ClusterNet Detecting Small Objects in Large Scene.pdf:application/pdf},
}

@inproceedings{rezaei_background_2017,
	address = {Venice, Italy},
	title = {Background {Subtraction} via {Fast} {Robust} {Matrix} {Completion}},
	isbn = {978-1-5386-1034-3},
	url = {http://ieeexplore.ieee.org/document/8265431/},
	doi = {10.1109/ICCVW.2017.221},
	abstract = {Background subtraction is the primary task of the majority of video inspection systems. The most important part of the background subtraction which is common among different algorithms is background modeling. In this regard, our paper addresses the problem of background modeling in a computationally efﬁcient way, which is important for current eruption of ”big data” processing coming from high resolution multi-channel videos. Our model is based on the assumption that background in natural images lies on a low-dimensional subspace. We formulated and solved this problem in a low-rank matrix completion framework. In modeling the background, we beneﬁted from the in-face extended Frank-Wolfe algorithm for solving a deﬁned convex optimization problem. We evaluated our fast robust matrix completion (fRMC) method on both background models challenge (BMC) and Stuttgart artiﬁcial background subtraction (SABS) datasets. The results were compared with the robust principle component analysis (RPCA) and lowrank robust matrix completion (RMC) methods, both solved by inexact augmented Lagrangian multiplier (IALM). The results showed faster computation, at least twice as when IALM solver is used, while having a comparable accuracy even better in some challenges, in subtracting the backgrounds in order to detect moving objects in the scene.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {2017 {IEEE} {International} {Conference} on {Computer} {Vision} {Workshops} ({ICCVW})},
	publisher = {IEEE},
	author = {Rezaei, Behnaz and Ostadabbas, Sarah},
	month = oct,
	year = {2017},
	pages = {1871--1879},
	file = {Rezaei and Ostadabbas - 2017 - Background Subtraction via Fast Robust Matrix Comp.pdf:C\:\\Users\\chris\\Zotero\\storage\\49RYWV6K\\Rezaei and Ostadabbas - 2017 - Background Subtraction via Fast Robust Matrix Comp.pdf:application/pdf},
}

@article{xiaowei_zhou_moving_2013,
	title = {Moving {Object} {Detection} by {Detecting} {Contiguous} {Outliers} in the {Low}-{Rank} {Representation}},
	volume = {35},
	issn = {0162-8828, 2160-9292},
	url = {http://ieeexplore.ieee.org/document/6216381/},
	doi = {10.1109/TPAMI.2012.132},
	abstract = {Object detection is a fundamental step for automated video analysis in many vision applications. Object detection in a video is usually performed by object detectors or background subtraction techniques. Often, an object detector requires manually labeled examples to train a binary classifier, while background subtraction needs a training sequence that contains no objects to build a background model. To automate the analysis, object detection without a separate training phase becomes a critical task. People have tried to tackle this task by using motion information. But existing motion-based methods are usually limited when coping with complex scenarios such as nonrigid motion and dynamic background. In this paper, we show that the above challenges can be addressed in a unified framework named DEtecting Contiguous Outliers in the LOw-rank Representation (DECOLOR). This formulation integrates object detection and background learning into a single process of optimization, which can be solved by an alternating algorithm efficiently. We explain the relations between DECOLOR and other sparsity-based methods. Experiments on both simulated data and real sequences demonstrate that DECOLOR outperforms the state-of-the-art approaches and it can work effectively on a wide range of complex scenarios.},
	language = {en},
	number = {3},
	urldate = {2022-06-16},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {{Xiaowei Zhou} and {Can Yang} and {Weichuan Yu}},
	month = mar,
	year = {2013},
	pages = {597--610},
	file = {Xiaowei Zhou et al. - 2013 - Moving Object Detection by Detecting Contiguous Ou.pdf:C\:\\Users\\chris\\Zotero\\storage\\36ZVXQSP\\Xiaowei Zhou et al. - 2013 - Moving Object Detection by Detecting Contiguous Ou.pdf:application/pdf},
}

@article{zhou_godec_nodate,
	title = {{GoDec}: {Randomized} {Low}-rank \& {Sparse} {Matrix} {Decomposition} in {Noisy} {Case}},
	abstract = {Low-rank and sparse structures have been profoundly studied in matrix completion and compressed sensing. In this paper, we develop “Go Decomposition” (GoDec) to efﬁciently and robustly estimate the low-rank part L and the sparse part S of a matrix X = L + S + G with noise G. GoDec alternatively assigns the low-rank approximation of X − S to L and the sparse approximation of X − L to S. The algorithm can be signiﬁcantly accelerated by bilateral random projections (BRP). We also propose GoDec for matrix completion as an important variant. We prove that the objective value ∥X − L − S∥2F converges to a local minimum, while L and S linearly converge to local optimums. Theoretically, we analyze the inﬂuence of L, S and G to the asymptotic/convergence speeds in order to discover the robustness of GoDec. Empirical studies suggest the efﬁciency, robustness and effectiveness of GoDec comparing with representative matrix decomposition and completion tools, e.g., Robust PCA and OptSpace.},
	language = {en},
	author = {Zhou, Tianyi and Tao, Dacheng},
	pages = {16},
	file = {Zhou and Tao - GoDec Randomized Low-rank & Sparse Matrix Decompo.pdf:C\:\\Users\\chris\\Zotero\\storage\\HKZPB3DJ\\Zhou and Tao - GoDec Randomized Low-rank & Sparse Matrix Decompo.pdf:application/pdf},
}

@inproceedings{rodriguez_fast_2013,
	address = {Melbourne, Australia},
	title = {Fast principal component pursuit via alternating minimization},
	isbn = {978-1-4799-2341-0},
	url = {http://ieeexplore.ieee.org/document/6738015/},
	doi = {10.1109/ICIP.2013.6738015},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {2013 {IEEE} {International} {Conference} on {Image} {Processing}},
	publisher = {IEEE},
	author = {Rodriguez, Paul and Wohlberg, Brendt},
	month = sep,
	year = {2013},
	pages = {69--73},
	file = {Rodriguez and Wohlberg - 2013 - Fast principal component pursuit via alternating m.pdf:C\:\\Users\\chris\\Zotero\\storage\\ILNY6BLA\\Rodriguez and Wohlberg - 2013 - Fast principal component pursuit via alternating m.pdf:application/pdf},
}

@article{barnich_vibe_2011,
	title = {{ViBe}: {A} {Universal} {Background} {Subtraction} {Algorithm} for {Video} {Sequences}},
	volume = {20},
	issn = {1057-7149, 1941-0042},
	shorttitle = {{ViBe}},
	url = {http://ieeexplore.ieee.org/document/5672785/},
	doi = {10.1109/TIP.2010.2101613},
	abstract = {This paper presents a technique for motion detection that incorporates several innovative mechanisms. For example, our proposed technique stores, for each pixel, a set of values taken in the past at the same location or in the neighborhood. It then compares this set to the current pixel value in order to determine whether that pixel belongs to the background, and adapts the model by choosing randomly which values to substitute from the background model. This approach differs from those based upon the classical belief that the oldest values should be replaced ﬁrst. Finally, when the pixel is found to be part of the background, its value is propagated into the background model of a neighboring pixel. We describe our method in full details (including pseudo-code and the parameter values used) and compare it to other background subtraction techniques. Efﬁciency ﬁgures show that our method outperforms recent and proven state-of-the-art methods in terms of both computation speed and detection rate. We also analyze the performance of a downscaled version of our algorithm to the absolute minimum of one comparison and one byte of memory per pixel. It appears that even such a simpliﬁed version of our algorithm performs better than mainstream techniques.},
	language = {en},
	number = {6},
	urldate = {2022-06-16},
	journal = {IEEE Transactions on Image Processing},
	author = {Barnich, O and Van Droogenbroeck, M},
	month = jun,
	year = {2011},
	pages = {1709--1724},
	file = {Barnich and Van Droogenbroeck - 2011 - ViBe A Universal Background Subtraction Algorithm.pdf:C\:\\Users\\chris\\Zotero\\storage\\S7C62KXQ\\Barnich and Van Droogenbroeck - 2011 - ViBe A Universal Background Subtraction Algorithm.pdf:application/pdf},
}

@article{horng-horng_lin_regularized_2011,
	title = {Regularized {Background} {Adaptation}: {A} {Novel} {Learning} {Rate} {Control} {Scheme} for {Gaussian} {Mixture} {Modeling}},
	volume = {20},
	issn = {1057-7149, 1941-0042},
	shorttitle = {Regularized {Background} {Adaptation}},
	url = {http://ieeexplore.ieee.org/document/5570957/},
	doi = {10.1109/TIP.2010.2075938},
	abstract = {To model a scene for background subtraction, Gaussian mixture modeling (GMM) is a popular choice for its capability of adaptation to background variations. However, GMM often suffers from a tradeoff between robustness to background changes and sensitivity to foreground abnormalities and is inefﬁcient in managing the tradeoff for various surveillance scenarios. By reviewing the formulations of GMM, we identify that such a tradeoff can be easily controlled by adaptive adjustments of the GMM’s learning rates for image pixels at different locations and of distinct properties. A new rate control scheme based on high-level feedback is then developed to provide better regularization of background adaptation for GMM and to help resolving the tradeoff. Additionally, to handle lighting variations that change too fast to be caught by GMM, a heuristic rooting in frame difference is proposed to assist the proposed rate control scheme for reducing false foreground alarms. Experiments show the proposed learning rate control scheme, together with the heuristic for adaptation of over-quick lighting change, gives better performance than conventional GMM approaches.},
	language = {en},
	number = {3},
	urldate = {2022-06-16},
	journal = {IEEE Transactions on Image Processing},
	author = {{Horng-Horng Lin} and {Jen-Hui Chuang} and {Tyng-Luh Liu}},
	month = mar,
	year = {2011},
	pages = {822--836},
	file = {Horng-Horng Lin et al. - 2011 - Regularized Background Adaptation A Novel Learnin.pdf:C\:\\Users\\chris\\Zotero\\storage\\I3RQ3M5N\\Horng-Horng Lin et al. - 2011 - Regularized Background Adaptation A Novel Learnin.pdf:application/pdf},
}

@article{zivkovic_efficient_2006,
	title = {Efficient adaptive density estimation per image pixel for the task of background subtraction},
	volume = {27},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167865505003521},
	doi = {10.1016/j.patrec.2005.11.005},
	abstract = {We analyze the computer vision task of pixel-level background subtraction. We present recursive equations that are used to constantly update the parameters of a Gaussian mixture model and to simultaneously select the appropriate number of components for each pixel. We also present a simple non-parametric adaptive density estimation method. The two methods are compared with each other and with some previously proposed algorithms.},
	language = {en},
	number = {7},
	urldate = {2022-06-16},
	journal = {Pattern Recognition Letters},
	author = {Zivkovic, Zoran and van der Heijden, Ferdinand},
	month = may,
	year = {2006},
	pages = {773--780},
	file = {Zivkovic and van der Heijden - 2006 - Efficient adaptive density estimation per image pi.pdf:C\:\\Users\\chris\\Zotero\\storage\\I3IPXMAI\\Zivkovic and van der Heijden - 2006 - Efficient adaptive density estimation per image pi.pdf:application/pdf},
}

@inproceedings{gutchess_background_2001,
	address = {Vancouver, BC, Canada},
	title = {A background model initialization algorithm for video surveillance},
	volume = {1},
	isbn = {978-0-7695-1143-6},
	url = {http://ieeexplore.ieee.org/document/937598/},
	doi = {10.1109/ICCV.2001.937598},
	abstract = {Many motion detection and tracking algorithms rely on the process of background subtraction, a technique which detects changes from a model of the background scene. We present a new algorithm for the purpose of background model initialization. The algorithm takes as input a video sequence in which moving objects are present, and outputs a statistical background model describing the static parts of the scene. Multiple hypotheses of the background value at each pixel are generated by locating periods of stable intensity in the sequence. The likelihood of each hypothesis is then evaluated using optical flow information from the neighborhood around the pixel, and the most likely hypothesis is chosen to represent the background. Our results are compared with those of several standard background modeling techniques using surveillance video of humans in indoor environments.},
	language = {en},
	urldate = {2022-06-16},
	booktitle = {Proceedings {Eighth} {IEEE} {International} {Conference} on {Computer} {Vision}. {ICCV} 2001},
	publisher = {IEEE Comput. Soc},
	author = {Gutchess, D. and Trajkovics, M. and Cohen-Solal, E. and Lyons, D. and Jain, A.K.},
	year = {2001},
	pages = {733--740},
	file = {Gutchess et al. - 2001 - A background model initialization algorithm for vi.pdf:C\:\\Users\\chris\\Zotero\\storage\\PPRGJRHZ\\Gutchess et al. - 2001 - A background model initialization algorithm for vi.pdf:application/pdf},
}

@article{cao_two_2015,
	title = {Two {Algorithms} for the {Detection} and {Tracking} of {Moving} {Vehicle} {Targets} in {Aerial} {Infrared} {Image} {Sequences}},
	volume = {8},
	issn = {2072-4292},
	url = {http://www.mdpi.com/2072-4292/8/1/28},
	doi = {10.3390/rs8010028},
	abstract = {In this paper, by analyzing the characteristics of infrared moving targets, a Symmetric Frame Differencing Target Detection algorithm based on local clustering segmentation is proposed. In consideration of the high real-time performance and accuracy of traditional symmetric differencing, this novel algorithm uses local grayscale clustering to accomplish target detection after carrying out symmetric frame differencing to locate the regions of change. In addition, the mean shift tracking algorithm is also improved to solve the problem of missed targets caused by error convergence. As a result, a kernel-based mean shift target tracking algorithm based on detection updates is also proposed. This tracking algorithm makes use of the interaction between detection and tracking to correct the tracking errors in real time and to realize robust target tracking in complex scenes. In addition, the validity, robustness and stability of the proposed algorithms are all veriﬁed by experiments on mid-infrared aerial sequences with vehicles as targets.},
	language = {en},
	number = {1},
	urldate = {2022-06-16},
	journal = {Remote Sensing},
	author = {Cao, Yutian and Wang, Gang and Yan, Dongmei and Zhao, Zhongming},
	month = dec,
	year = {2015},
	pages = {28},
	file = {Cao et al. - 2015 - Two Algorithms for the Detection and Tracking of M.pdf:C\:\\Users\\chris\\Zotero\\storage\\HYK8KFWA\\Cao et al. - 2015 - Two Algorithms for the Detection and Tracking of M.pdf:application/pdf},
}

@article{gautier_sherlock_2022,
	title = {Sherlock: {A} {Multi}-{Objective} {Design} {Space} {Exploration} {Framework}},
	volume = {27},
	issn = {1084-4309, 1557-7309},
	shorttitle = {Sherlock},
	url = {https://dl.acm.org/doi/10.1145/3511472},
	doi = {10.1145/3511472},
	abstract = {Design space exploration (DSE) provides intelligent methods to tune the large number of optimization parameters present in modern FPGA high-level synthesis tools. High-level synthesis parameter tuning is a time-consuming process due to lengthy hardware compilation times—synthesizing an FPGA design can take tens of hours. DSE helps find an optimal solution faster than brute-force methods without relying on designer intuition to achieve high-quality results. Sherlock is a DSE framework that can handle multiple conflicting optimization objectives and aggressively focuses on finding Pareto-optimal solutions. Sherlock integrates a model selection process to choose the regression model that helps reach the optimal solution faster. Sherlock designs a strategy based around the multi-armed bandit problem, opting to balance exploration and exploitation based on the learned and expected results. Sherlock can decrease the importance of models that do not provide correct estimates, reaching the optimal design faster. Sherlock is capable of tailoring its choice of regression models to the problem at hand, leading to a model that best reflects the application design space. We have tested the framework on a large dataset of FPGA design problems and found that Sherlock converges toward the set of optimal designs faster than similar frameworks.},
	language = {en},
	number = {4},
	urldate = {2022-06-16},
	journal = {ACM Transactions on Design Automation of Electronic Systems},
	author = {Gautier, Quentin and Althoff, Alric and Crutchfield, Christopher L. and Kastner, Ryan},
	month = jul,
	year = {2022},
	pages = {1--20},
	file = {Gautier et al. - 2022 - Sherlock A Multi-Objective Design Space Explorati.pdf:C\:\\Users\\chris\\Zotero\\storage\\J3U62DJV\\Gautier et al. - 2022 - Sherlock A Multi-Objective Design Space Explorati.pdf:application/pdf},
}

@article{yin_detecting_2022,
	title = {Detecting and {Tracking} {Small} and {Dense} {Moving} {Objects} in {Satellite} {Videos}: {A} {Benchmark}},
	volume = {60},
	issn = {0196-2892, 1558-0644},
	shorttitle = {Detecting and {Tracking} {Small} and {Dense} {Moving} {Objects} in {Satellite} {Videos}},
	url = {http://arxiv.org/abs/2111.12960},
	doi = {10.1109/TGRS.2021.3130436},
	abstract = {Satellite video cameras can provide continuous observation for a large-scale area, which is important for many remote sensing applications. However, achieving moving object detection and tracking in satellite videos remains challenging due to the insufﬁcient appearance information of objects and lack of high-quality datasets. In this paper, we ﬁrst build a largescale satellite video dataset with rich annotations for the task of moving object detection and tracking. This dataset is collected by the Jilin-1 satellite constellation and composed of 47 high-quality videos with 1,646,038 instances of interest for object detection and 3,711 trajectories for object tracking. We then introduce a motion modeling baseline to improve the detection rate and reduce false alarms based on accumulative multi-frame differencing and robust matrix completion. Finally, we establish the ﬁrst public benchmark for moving object detection and tracking in satellite videos, and extensively evaluate the performance of several representative approaches on our dataset. Comprehensive experimental analyses and insightful conclusions are also provided. The dataset is available at https://github.com/QingyongHu/VISO.},
	language = {en},
	urldate = {2022-05-01},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	author = {Yin, Qian and Hu, Qingyong and Liu, Hao and Zhang, Feng and Wang, Yingqian and Lin, Zaiping and An, Wei and Guo, Yulan},
	year = {2022},
	note = {arXiv: 2111.12960},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {1--18},
	annote = {Comment: This paper has been accepted by IEEE Transactions on Geoscience and Remote Sensing. Qian Yin and Qingyong Hu have equal contributions to this work and are co-first authors. The dataset is available at https://github.com/QingyongHu/VISO},
	file = {Yin et al. - 2022 - Detecting and Tracking Small and Dense Moving Obje.pdf:C\:\\Users\\chris\\Zotero\\storage\\2LT9LP4E\\Yin et al. - 2022 - Detecting and Tracking Small and Dense Moving Obje.pdf:application/pdf},
}

@article{haalck_towards_2020,
	title = {Towards image-based animal tracking in natural environments using a freely moving camera},
	volume = {330},
	issn = {01650270},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0165027019303127},
	doi = {10.1016/j.jneumeth.2019.108455},
	abstract = {Background: Image-based tracking of individual animals can provide rich data to underpin breakthroughs in biological and medical research, but few if any existing methods extend to tracking unconstrained natural behaviour in the ﬁeld. New method: We have developed a visual tracking system for animals ﬁlmed with a freely moving hand-held or drone-operated camera in their natural environment. This exploits a global inference method for detecting motion of an animal against a cluttered background. Trajectories are then generated by a novel video key-frame selection scheme in combination with a geometrically constrained image stitching algorithm, resulting in a twodimensional panorama image of the environment on which the dense animal path is displayed.
Results: By introducing a minimal and plausible set of constraints regarding the camera orientation and movement, we demonstrate that both per-frame animal positions and overall trajectories can be extracted with reasonable accuracy, for a range of diﬀerent animals, environments and imaging modalities.
Comparison: Our method requires only a single uncalibrated camera, does not require marking or training data to detect the animal, and makes no prior assumptions about appearance of the target or background. In particular it can detect targets occupying fewer than 20 pixels in the image, and deal with poor contrast, highly dynamic lighting and frequent occlusion.
Conclusion: Our algorithm produces highly informative qualitative trajectories embedded in a panorama of the environment. The results are still subject to rotational drift and additional scaling routines would be needed to obtain absolute real-world coordinates. It nevertheless provides a ﬂexible and easy-to-use system to obtain rich data on natural animal behaviour in the ﬁeld.},
	language = {en},
	urldate = {2021-07-28},
	journal = {Journal of Neuroscience Methods},
	author = {Haalck, Lars and Mangan, Michael and Webb, Barbara and Risse, Benjamin},
	month = jan,
	year = {2020},
	pages = {108455},
	file = {Haalck et al. - 2020 - Towards image-based animal tracking in natural env.pdf:C\:\\Users\\chris\\Zotero\\storage\\R8RXI9YN\\Haalck et al. - 2020 - Towards image-based animal tracking in natural env.pdf:application/pdf},
}

@inproceedings{jaward_multiple_2006,
	address = {Big Sky, MT, USA},
	title = {Multiple {Object} {Tracking} {Using} {Particle} {Filters}},
	isbn = {978-0-7803-9545-9},
	url = {http://ieeexplore.ieee.org/document/1655926/},
	doi = {10.1109/AERO.2006.1655926},
	abstract = {The particle ﬁltering technique with multiple cues such as colour, texture and edges as observation features is a powerful technique for tracking deformable objects in image sequences with complex backgrounds. In this paper, our recent work [1] on single object tracking using particle ﬁlters is extended to multiple objects. In the proposed scheme, track initialisation is embedded in the particle ﬁlter without relying on an external object detection scheme. The proposed scheme avoids the use of hybrid state estimation for the estimation of number of active objects and its associated state vectors as proposed in [2]. The number of active objects and track management are handled by means of probabilities of the number of active objects in a given frame. These probabilities are shown to be easily estimated by the Monte Carlo data association algorithm used in our algorithm.},
	language = {en},
	urldate = {2021-07-02},
	booktitle = {2006 {IEEE} {Aerospace} {Conference}},
	publisher = {IEEE},
	author = {Jaward, M. and Mihaylova, L. and Canagarajah, N. and Bull, D.},
	year = {2006},
	pages = {1--8},
	file = {Jaward et al. - 2006 - Multiple Object Tracking Using Particle Filters.pdf:C\:\\Users\\chris\\Zotero\\storage\\C2RNV7TN\\Jaward et al. - 2006 - Multiple Object Tracking Using Particle Filters.pdf:application/pdf},
}

@article{tan_efficientnet_2020,
	title = {{EfficientNet}: {Rethinking} {Model} {Scaling} for {Convolutional} {Neural} {Networks}},
	shorttitle = {{EfficientNet}},
	url = {http://arxiv.org/abs/1905.11946},
	abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a ﬁxed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefﬁcient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet.},
	language = {en},
	urldate = {2021-06-06},
	journal = {arXiv:1905.11946 [cs, stat]},
	author = {Tan, Mingxing and Le, Quoc V.},
	month = sep,
	year = {2020},
	note = {arXiv: 1905.11946},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	annote = {Comment: ICML 2019},
	annote = {We attempted to use EfficientNet, but did not find success due to our data not being separable},
	file = {Tan and Le - 2020 - EfficientNet Rethinking Model Scaling for Convolu.pdf:C\:\\Users\\chris\\Zotero\\storage\\INLZID4C\\Tan and Le - 2020 - EfficientNet Rethinking Model Scaling for Convolu.pdf:application/pdf},
}

@article{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 × 3) convolution ﬁlters, which shows that a signiﬁcant improvement on the prior-art conﬁgurations can be achieved by pushing the depth to 16–19 weight layers. These ﬁndings were the basis of our ImageNet Challenge 2014 submission, where our team secured the ﬁrst and the second places in the localisation and classiﬁcation tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	language = {en},
	urldate = {2021-06-06},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {We've tried using VGG16, the issues are the same as EfficientNet.},
	file = {Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:C\:\\Users\\chris\\Zotero\\storage\\MV5QSLZE\\Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf},
}

@inproceedings{rublee_orb_2011,
	address = {Barcelona, Spain},
	title = {{ORB}: {An} efficient alternative to {SIFT} or {SURF}},
	isbn = {978-1-4577-1102-2 978-1-4577-1101-5 978-1-4577-1100-8},
	shorttitle = {{ORB}},
	url = {http://ieeexplore.ieee.org/document/6126544/},
	doi = {10.1109/ICCV.2011.6126544},
	abstract = {Feature matching is at the base of many computer vi­ sion problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for de­ tection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magni­ tude faster than SIFT, while peiforming as well in many situations. The efficiency is tested on several real-world ap­ plications, including object detection and patch-tracking on a smart phone.},
	language = {en},
	urldate = {2021-06-06},
	booktitle = {2011 {International} {Conference} on {Computer} {Vision}},
	publisher = {IEEE},
	author = {Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
	month = nov,
	year = {2011},
	pages = {2564--2571},
	annote = {We use ORB's descriptor but not it's feature detector.  We use FAST instead.},
	file = {Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:C\:\\Users\\chris\\Zotero\\storage\\6FVHUX8M\\Rublee et al. - 2011 - ORB An efficient alternative to SIFT or SURF.pdf:application/pdf},
}

@article{bailo_efficient_2018,
	title = {Efficient adaptive non-maximal suppression algorithms for homogeneous spatial keypoint distribution},
	volume = {106},
	issn = {01678655},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016786551830062X},
	doi = {10.1016/j.patrec.2018.02.020},
	abstract = {Keypoint detection usually results in a large number of keypoints which are mostly clustered, redundant, and noisy. These keypoints often require special processing like Adaptive Non-Maximal Suppression (ANMS) to retain the most relevant ones. In this paper, we present three new eﬃcient ANMS approaches which ensure a fast and homogeneous repartition of the keypoints in the image. For this purpose, a square approximation of the search range to suppress irrelevant points is proposed to reduce the computational complexity of the ANMS. To further speed up the proposed approaches, we also introduce a novel strategy to initialize the search range based on image dimension which leads to a faster convergence. An exhaustive survey and comparisons with already existing methods are provided to highlight the eﬀectiveness and scalability of our methods and the initialization strategy.},
	language = {en},
	urldate = {2021-06-06},
	journal = {Pattern Recognition Letters},
	author = {Bailo, Oleksandr and Rameau, Francois and Joo, Kyungdon and Park, Jinsun and Bogdan, Oleksandr and Kweon, In So},
	month = apr,
	year = {2018},
	pages = {53--60},
	annote = {We are using this to ensure that our keypoints are well distributed},
	file = {Bailo et al. - 2018 - Efficient adaptive non-maximal suppression algorit.pdf:C\:\\Users\\chris\\Zotero\\storage\\DS3FW63D\\Bailo et al. - 2018 - Efficient adaptive non-maximal suppression algorit.pdf:application/pdf},
}

@article{ray_efficient_2017,
	title = {An {Efficient} {Approach} for {Object} {Detection} and {Tracking} of {Objects} in a {Video} with {Variable} {Background}},
	url = {http://arxiv.org/abs/1706.02672},
	abstract = {This paper proposes a novel approach to create an automated visual surveillance system which is very efficient in detecting and tracking moving objects in a video captured by moving camera without any apriori information about the captured scene. Separating foreground from the background is challenging job in videos captured by moving camera as both foreground and background information change in every consecutive frames of the image sequence; thus a pseudo-motion is perceptive in background. In the proposed algorithm, the pseudo-motion in background is estimated and compensated using phase correlation of consecutive frames based on the principle of Fourier shift theorem. Then a method is proposed to model an acting background from recent history of commonality of the current frame and the foreground is detected by the differences between the background model and the current frame. Further exploiting the recent history of dissimilarities of the current frame, actual moving objects are detected in the foreground. Next, a two-stepped morphological operation is proposed to refine the object region for an optimum object size. Each object is attributed by its centroid, dimension and three highest peaks of its gray value histogram. Finally, each object is tracked using Kalman filter based on its attributes. The major advantage of this algorithm over most of the existing object detection and tracking algorithms is that, it does not require initialization of object position in the first frame or training on sample data to perform. Performance of the algorithm is tested on benchmark videos containing variable background and very satisfiable results is achieved. The performance of the algorithm is also comparable with some of the state-of-the-art algorithms for object detection and tracking.},
	urldate = {2020-03-23},
	journal = {arXiv:1706.02672 [cs]},
	author = {Ray, Kumar S. and Chakraborty, Soma},
	month = may,
	year = {2017},
	note = {arXiv: 1706.02672},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {This is a foundational paper, we do not implement all aspects though},
	file = {An Efficient Approach for Object Detection and Tracking of Objects in a Video with Variable Background.pdf:C\:\\Users\\chris\\Zotero\\storage\\RAB6IIBB\\An Efficient Approach for Object Detection and Tracking of Objects in a Video with Variable Background.pdf:application/pdf},
}
